{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfeats\n",
    "from typing import *\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llf = LowLevelFeatureExtractor(**param_list[0])\n",
    "\n",
    "# root_folder = \"C:\\\\Users\\\\trong\\\\Documents\\\\skin_data\"\n",
    "root_folder = \"/mnt/c/Users/trong/Documents/skin_data\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
    "    transforms.Grayscale(num_output_channels=1),    # Convert to grayscale\n",
    "    ToNumpy(),  # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CSVImageMetadataDataset(csv_file='./data/vaynen_train_linux.csv', root_dir=root_folder, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)   \n",
    "\n",
    "test_dataset = CSVImageMetadataDataset(csv_file='./data/vaynen_test_linux.csv', root_dir=root_folder, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Check one batch\n",
    "images, metadata, labels = next(iter(train_dataloader))\n",
    "print(images.shape)  # Example: torch.Size([32, 3, 128, 128])\n",
    "print(metadata.shape)  # Example: torch.Size([32, 6])  -> 6 metadata features\n",
    "print(labels.shape)  # Example: torch.Size([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 0])\n",
      "torch.Size([32, 22])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CSVMetadataDataset(csv_file=\"./data/fos/vaynen_train_fos.csv\", root_dir=root_folder)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)   \n",
    "\n",
    "test_dataset = CSVMetadataDataset(csv_file=\"./data/fos/vaynen_test_fos.csv\", root_dir=root_folder)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Check one batch\n",
    "images, metadata, labels = next(iter(train_dataloader))\n",
    "print(images.shape)  # Example: torch.Size([32, 3, 128, 128])\n",
    "print(metadata.shape)  # Example: torch.Size([32, 6])  -> 6 metadata features\n",
    "print(labels.shape)  # Example: torch.Size([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNeuralNetwork(\n",
      "  (fc1): Linear(in_features=22, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (swish): SwishActivation()\n",
      "  (batchNorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNeuralNetwork(inputs = llf.get_features_size())\n",
    "\n",
    "# Check the model's architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.015433703656120701: 100%|██████████| 30/30 [00:58<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fos complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, epochs=30, llf=llf ,features_set=llf.function.__name__, ) #10 - 15 is already enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 71.7094017094017% On fos'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, test_dataloader,llf=llf, features_set=llf.function.__name__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
